apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: birthdaypipeline
  namespace: default
  labels:
    app: birthdaypipeline
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "birthday-spark-image"
  mainApplicationFile: local:///opt/application/BirthdayDataPipeline.py
  sparkVersion: "3.5"
  arguments: ["--database=local"]
  restartPolicy:
    type: Never

  sparkConf:
    "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
    "spark.ui.port": "4040"

    "spark.driver.extraJavaOptions": "-Divy.cache.dir=/tmp/ivy-cache -Divy.home=/tmp/ivy-cache"
    "spark.executor.extraJavaOptions": "-Divy.cache.dir=/tmp/ivy-cache -Divy.home=/tmp/ivy-cache"
    "spark.jars.ivy": "/tmp/ivy"

    "spark.jars.packages": "org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.103.0,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.8.0,org.apache.iceberg:iceberg-aws-bundle:1.8.0"
    "spark.sql.extensions": "org.projectnessie.spark.extensions.NessieSparkSessionExtensions,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"
    "spark.sql.catalog.nessie.uri": "http://nessie:19120/iceberg"
    "spark.sql.catalog.nessie.type": "rest"
    "spark.sql.catalog.nessie": "org.apache.iceberg.spark.SparkCatalog"
    "spark.sql.catalog.nessie.warehouse": "warehouse"


  timeToLiveSeconds: 300
  deps: {}

  driver:
    memory: "1g"

  executor:
    instances: 1
    memory: "1g"

  dynamicAllocation:
    enabled: true
    initialExecutors: 1
    minExecutors: 1
    maxExecutors: 1
